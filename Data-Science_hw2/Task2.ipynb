{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data, Split to train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sorting data by time\n",
    "rdd =  sc.textFile(RATINGS_10M).map(lambda line: [float(x) for x in line.split('::')]).sortBy(lambda x: x[3],False)\n",
    "size = rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processing data to structure: Rating(user=62510, product=34148, rating=3.0)\n",
    "train = rdd.zipWithIndex().filter(lambda x: x[-1] < size*0.6).map(lambda x: Rating(int(x[0][0]), int(x[0][1]), x[0][2]))\n",
    "testdata = rdd.zipWithIndex().filter(lambda x: x[-1] > size*0.6).map(lambda x: Rating(int(x[0][0]), int(x[0][1]), x[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute user bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "test = sc.parallelize([(1,3), (3,4), (1,3), (1,4)])\n",
    "\n",
    "print test.map(lambda data: (data[0], 1)).reduceByKey(lambda a,b: a+1).collectAsMap()\n",
    "#Test counter\n",
    "'''\n",
    "user_count = train.map(lambda data: (data[0], 1)).reduceByKey(lambda a,b: a+1).collectAsMap()\n",
    "score_mean = train.map(lambda data: data[2]).mean()\n",
    "user_score_bias_sum = train.map(lambda data: (data[0], data[2] - score_mean)).reduceByKey(lambda a,b: a+b).collectAsMap()\n",
    "user_bias = {}\n",
    "for key in user_count.keys():\n",
    "    user_bias[key] = user_score_bias_sum[key]/user_count[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute movie bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_count = train.map(lambda rating: (rating.product, 1)).reduceByKey(lambda a,b: a+1).collectAsMap()\n",
    "movie_score_bias_sum = train.map(test).reduceByKey(lambda a,b: a+b).collectAsMap()\n",
    "#lambda rating: (rating.product, rating.rating - score_mean  - user_bias[rating.user] )\n",
    "def test(rating):\n",
    "    print user_bias[rating.user]\n",
    "    return (rating.product, rating.rating - score_mean)\n",
    "movie_bias = {}\n",
    "for key in movie_count.keys():\n",
    "    movie_bias[key] = movie_score_bias_sum[key]/movie_count[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "test = sc.parallelize([(1,3), (3,4), (1,3), (1,4)])\n",
    "def f(x): return (x[0], x[1]**2)\n",
    "print test.map(f).collect()\n",
    "'''\n",
    "\n",
    "train_rm_user = train.map(lambda rating: Rating(rating.user, rating.product, rating.rating - user_bias[rating.user]))\n",
    "train_rm_movie = train.map(lambda rating: Rating(rating.user, rating.product, rating.rating - user_bias[rating.user] - movie_bias[rating.product]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating(user=62510, product=34148, rating=3.0)\n",
      "Rating(user=62510, product=34148, rating=2.5208408027796696)\n",
      "Rating(user=62510, product=34148, rating=-0.644382205610396)\n"
     ]
    }
   ],
   "source": [
    "#print movie_count\n",
    "#print movie_score_bias_sum\n",
    "#print movie_bias\n",
    "print train.first()\n",
    "print train_rm_user.first()\n",
    "print train_rm_movie.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_train = rdd.zipWithIndex().filter(lambda x: x[-1] < size*0.6).map(lambda x: (x[0][0], float(x[0][2])))\n",
    "product_train = rdd.zipWithIndex().filter(lambda x: x[-1] < size*0.6).map(lambda x: (x[0][1], float(x[0][2])))\n",
    "print \"train user\"\n",
    "user_clusters = KMeans.train(user_train, int(len(user_bias)/2), maxIterations=20, initializationMode=\"random\")\n",
    "print \"train cluster\"\n",
    "product_clusters = KMeans.train(product_train, int(len(movie_bias)/2), maxIterations=20, initializationMode=\"random\")\n",
    "\n",
    "def convert(data):\n",
    "    user = predict(data[0], float(x[2]))\n",
    "    product = predict(data[1], float(user[1]))\n",
    "    return (user[0], product[0], product[1])\n",
    "def predict(point):\n",
    "    category = clusters.predict(point)\n",
    "    center = clusters.centers[category]\n",
    "    return (category, center[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_reduce = rdd.zipWithIndex().filter(lambda x: x[-1] < size*0.6)\\\n",
    "        .map(lambda x: (x[0][0], x[0][1], x[0][2])).map(convert).map(lambda x: Rating(int(x[0]), int(x[1]), x[2]))\n",
    "validate_reduce = rdd.zipWithIndex().filter(lambda x: size*0.6<=x[-1] < size*0.8)\\\n",
    "        .map(lambda x: (x[0][0], x[0][1], x[0][2])).map(convert).map(lambda x: Rating(int(x[0]), int(x[1]), x[2]))\n",
    "test_reduce = rdd.zipWithIndex().filter(lambda x: size*0.6<=x[-1] < size*0.8)\\\n",
    "        .map(lambda x: (x[0][0], x[0][1], x[0][2])).map(convert).map(lambda x: Rating(int(x[0]), int(x[1]), x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"save data\"\n",
    "user_clusters.save(sc, \"userModel\")\n",
    "product_clusters.save(sc, \"productModel\")\n",
    "train_reduce_list = train_reduce.collect()\n",
    "validate_reduce_list = validate_reduce.collect()\n",
    "test_reduce = test_reduce.collect()\n",
    "with open(DATA_FOLDER + \"train.dat\", \"wb\") as f:\n",
    "    for rating in train_reduce_list:\n",
    "        f.write(str(rating.user) + \"::\" + str(rating.product) + \"::\" + str(rating.rating) + \"\\n\")\n",
    "\n",
    "with open(DATA_FOLDER + \"validate.dat\", \"wb\") as f:\n",
    "    for rating in validate_reduce:\n",
    "        f.write(str(rating.user) + \"::\" + str(rating.product) + \"::\" + str(rating.rating) + \"\\n\")\n",
    "\n",
    "with open(DATA_FOLDER + \"test.dat\", \"wb\") as f:\n",
    "    for rating in test_reduce:\n",
    "        f.write(str(rating.user) + \"::\" + str(rating.product) + \"::\" + str(rating.rating) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print train_reduce.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training ALS Model\n",
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(train, rank, numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying model evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((54040, 912), 4.367416929660967)\n",
      "((31630, 1412), (4.0, 4.163697460854653))\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predictAll(test).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = testdata.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 1.00137982702\n"
     ]
    }
   ],
   "source": [
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying recommendation System \n",
    "\n",
    "#testdata = train.map(lambda p: (p[0], p[1]))\n",
    "testUsers = train.map(lambda p: p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.recommendProducts(testUsers, 100)\n",
    "\n",
    "#predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "#ratesAndPreds = train.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "#print(\"Mean Squared Error = \" + str(MSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
